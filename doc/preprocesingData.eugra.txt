# MICRO server


When I access in the server, I found me in /mnt/picea/home/aabenitez. First, I
access to my data folder and link the Seidr network file. Then, with seidr tool, I transform it 
in a txt file to be exported outside of the server.

> cd Git/data/
> mkdir eucalyptus
> cd eucalyptus
> ln -s /mnt/picea/projects/eucalyptus/nstreet/eucgenie/seidr_2020/egrandis_exatlas/backbone/backbone-10-percent.sf .
> module load bioinfo-tools
> module load seidr-devel
> seidr view -c backbone-10-percent.sf > eugra_network.tsv
> exit

# LOCALHOST

First, I retrieve the files I need to my preprocessing analysis: The Seidr network in a txt format and the 
STRING file including the PPI with meaning links.

> scp micro:~/Git/data/eucalyptus/eugra_network.tsv .
> wget https://stringdb-static.org/download/protein.actions.v11.0/71139.protein.actions.v11.0.txt.gz

The ids of both files are very different. For the STRING file the ids are from NCBI (71139.XP_XXXXXXXXX.X )
while the network includes a different id type (Eucgr.XXXXXX). Since we do not find any mapping file for both
ids, we decide to apply a BLAST using the networks sequences as a DB and the STRING protein sequence as a
queries. So the steps are as follows:

1. To create a folder and access to it:

> mkdir blast | cd

2. To download the FASTA files including the NCBI id and the ID used in the network:

> wget https://stringdb-static.org/download/protein.sequences.v11.0/71139.protein.sequences.v11.0.fa.gz
> wget ftp://plantgenie.org/Data/EucGenIE/Eucalyptus_grandis/v2.0/FASTA/Egrandis_297_v2.0.protein.fa.gz

3. To decompress the files:

> gzip -d 71139.protein.sequences.v11.0.fa.gz > 71139.protein.sequences.v11.0.fa
> gzip -d Egrandis_297_v2.0.protein.fa.gz > Egrandis_297_v2.0.protein.fa

4. Create the need folder for the blast analysis and add the downloaded files in the corresponding folders:

> mkdir blastdb queries fasta results blastdb_custom
> mv 71139.protein.sequences.v11.0.fa queries/
> mv Egrandis_297_v2.0.protein.fa blastdb_custom/

5. Create first a custom DB including the fasta file with the target ids:

> docker run --rm \
+    -v /home/aabenitez/work/blast/blastdb_custom:/blast/blastdb_custom:rw \
+    -v /home/aabenitez/work/blast/fasta:/blast/fasta:ro \
+    -w /blast/blastdb_custom \
+    ncbi/blast \
+    makeblastdb -in /blast/fasta/Egrandis_297_v2.0.protein.fa -dbtype prot \
+    -parse_seqids -out egrandis -title "Egrandis protein" \
+    -taxid 71139 -blastdb_version 5

6. To run BLAST:

> docker run --rm \
+  -v /home/aabenitez/work/blast/blastdb:/blast/blastdb:ro -v  /home/aabenitez/work/blast/blastdb_custom:/blast/blastdb_custom:ro \
+  -v /home/aabenitez/work/blast/queries:/blast/queries:ro \
+  -v /home/aabenitez/work/blast/results:/blast/results:rw \
+  ncbi/blast \
+  blastp -query /blast/queries/71139.protein.sequences.v11.0.fa  -num_threads 14 \
+  -db egrandis -outfmt 7 -out /blast/results/blastn.71139.out 

7. To move all files (the used fasta files and the results) to analyse in R:

mv results/blastn.71139.out ~/work/rstudio/String_Eucalyptus/
mv queries/71139.protein.sequences.v11.0.fa ~/work/rstudio/String_Eucalyptus/
mv blastdb_custom/Egrandis_297_v2.0.protein.fa ~/work/rstudio/String_Eucalyptus/

## RSTUDIO

There is a created R file called CreatedMapping.R. This file have several steps:

1. To combine the BLASTp results with the FASTA files from STRING and PlantGenie.
2. To keep the matchs with an Identity of 95% and the algigned length is over the 95% of the sequence lengths of compared genes.
3. To combine the best matches with the String network with protein actions.
4. To transform the From and To columns as gene id
5. To export the new STRING network with the gene ids as eugraV2.protein.actions.v11.0.txt

# Python

There is a Python file called eugra-preprocessing.py that preprocess two files: eugra_network.tsv and 
eugraV2.protein.actions.v11.0.txt to generate a unique file combining their content.